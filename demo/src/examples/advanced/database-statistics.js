#!/usr/bin/env node

/**
 * Use Case 4: Database Statistics and Coverage Analysis
 * 
 * Problem: You need to understand the scope and quality of the WordNet database.
 * Solution: Analyze database statistics and content coverage.
 * 
 * Real-world application: Data quality assessment, research planning, system design
 */

import { 
  words, 
  synsets, 
  senses,
  ilis,
  lexicons
} from 'wn-ts';
import { createWordnet, displaySynset, safeClose, runDemo } from '../shared/helpers.js';

console.log(`
ğŸ“Š Use Case 4: Database Statistics and Coverage Analysis
=======================================================

Problem: You need to understand the scope and quality of the WordNet database.
Solution: Analyze database statistics and content coverage.

Real-world application: Data quality assessment, research planning
`);

async function demonstrateDatabaseStatistics() {
  const wordnet = createWordnet('statistics');
  console.log('âœ… Wordnet initialized successfully');

  try {
    console.log(`
ğŸ” Example 1: Overall Database Statistics
========================================`);

    // Get overall statistics using Wordnet instance methods
    console.log('\nğŸ“Š Database Statistics:');
    
    const allLexicons = await lexicons();
    const allILIs = await ilis();
    const stats = await wordnet.getStatistics();

    console.log(`  ğŸ“ Total words: ${stats.totalWords}`);
    console.log(`  ğŸ“š Total synsets: ${stats.totalSynsets}`);
    console.log(`  ğŸ¯ Total senses: ${stats.totalSenses}`);
    console.log(`  ğŸŒ Total ILI entries: ${stats.totalILIs}`);
    console.log(`  ğŸ“– Total lexicons: ${stats.totalLexicons}`);

    console.log(`
ğŸ” Example 2: Lexicon Breakdown and Analysis
===========================================`);

    // Show lexicon breakdown
    console.log('\nğŸ“– Lexicon Breakdown:');
    allLexicons.forEach(lexicon => {
      console.log(`  â€¢ ${lexicon.id}: ${lexicon.label} (v${lexicon.version}, ${lexicon.language})`);
    });

    // Group by language
    const lexiconsByLanguage = {};
    allLexicons.forEach(lexicon => {
      const lang = lexicon.language;
      if (!lexiconsByLanguage[lang]) {
        lexiconsByLanguage[lang] = [];
      }
      lexiconsByLanguage[lang].push(lexicon);
    });

    console.log('\nğŸŒ Lexicons by Language:');
    Object.entries(lexiconsByLanguage).forEach(([lang, lexicons]) => {
      console.log(`  â€¢ ${lang.toUpperCase()}: ${lexicons.length} lexicons`);
      lexicons.forEach(lexicon => {
        console.log(`    - ${lexicon.id}: ${lexicon.label} (v${lexicon.version})`);
      });
    });

    console.log(`
ğŸ” Example 3: Data Quality Analysis
==================================`);

    // Analyze data quality using Wordnet instance methods
    console.log('\nğŸ” Data Quality Analysis:');
    
    const qualityMetrics = await wordnet.getDataQualityMetrics();
    
    console.log(`  ğŸŒ Synsets with ILI: ${qualityMetrics.synsetsWithILI}`);
    console.log(`  âŒ Synsets without ILI: ${qualityMetrics.synsetsWithoutILI}`);
    console.log(`  ğŸ“Š ILI coverage: ${qualityMetrics.iliCoveragePercentage.toFixed(2)}%`);
    console.log(`  ğŸ“­ Empty synsets: ${qualityMetrics.emptySynsets}`);
    console.log(`  ğŸ“ Synsets with definitions: ${qualityMetrics.synsetsWithDefinitions}`);

    console.log(`
ğŸ” Example 4: Word Coverage Analysis
===================================`);

    // Analyze word coverage for common words
    const commonWords = ['computer', 'information', 'happy', 'run', 'light', 'bank'];
    
    console.log('\nğŸ“ Word Coverage Analysis:');
    for (const word of commonWords) {
      const wordEntries = await words(word);
      const synsetEntries = await synsets(word);
      
      console.log(`\nğŸ” "${word}":`);
      console.log(`  ğŸ“ Word forms: ${wordEntries.length}`);
      console.log(`  ğŸ“š Synsets: ${synsetEntries.length}`);
      
      if (synsetEntries.length > 0) {
        // Group by part of speech
        const byPOS = {};
        synsetEntries.forEach(synset => {
          const pos = synset.partOfSpeech;
          if (!byPOS[pos]) byPOS[pos] = [];
          byPOS[pos].push(synset);
        });
        
        Object.entries(byPOS).forEach(([pos, synsets]) => {
          console.log(`    ${pos.toUpperCase()}: ${synsets.length} synsets`);
        });
        
        // Show detailed information for the first synset
        const firstSynset = synsetEntries[0];
        await displaySynset(firstSynset, 1);
      }
    }

    console.log(`
ğŸ” Example 5: Part-of-Speech Distribution
========================================`);

    // Analyze part-of-speech distribution using Wordnet instance methods
    console.log('\nğŸ“Š Part-of-Speech Distribution:');
    
    const posDistribution = await wordnet.getPartOfSpeechDistribution();
    
    console.log('\nğŸ“š Synsets by Part of Speech:');
    Object.entries(posDistribution).forEach(([pos, count]) => {
      const percentage = ((count / stats.totalSynsets) * 100).toFixed(2);
      console.log(`  â€¢ ${(pos || 'undefined').toUpperCase()}: ${count} synsets (${percentage}%)`);
    });

    console.log(`
ğŸ” Example 6: Synset Size Analysis
=================================`);

    // TODO: Synset size analysis is temporarily disabled due to stack overflow issues
    // with large databases. The getSynsetSizeAnalysis method needs optimization.
    console.log('\nğŸ“ Synset Size Analysis:');
    console.log('  âš ï¸  Temporarily disabled due to performance issues with large databases');
    console.log('  ğŸ“Š This feature will be re-enabled once the underlying method is optimized');
    
    // const sizeAnalysis = await wordnet.getSynsetSizeAnalysis();
    // console.log(`  ğŸ“Š Average synset size: ${sizeAnalysis.averageSize.toFixed(2)} words`);
    // console.log(`  ğŸ“ˆ Largest synset: ${sizeAnalysis.maxSize} words`);
    // console.log(`  ğŸ“‰ Smallest synset: ${sizeAnalysis.minSize} words`);
    
    // // Size distribution (print only the 10 most common sizes)
    // console.log('\nğŸ“Š Synset Size Distribution (Top 10 Most Common Sizes):');
    // const sizeDistEntries = Object.entries(sizeAnalysis.sizeDistribution);
    // sizeDistEntries.sort((a, b) => b[1] - a[1]); // Sort by count descending
    // sizeDistEntries.slice(0, 10).forEach(([size, count]) => {
    //   const percentage = ((count / stats.totalSynsets) * 100).toFixed(2);
    //   console.log(`  â€¢ ${size} words: ${count} synsets (${percentage}%)`);
    // });

    console.log(`
ğŸ” Example 7: ILI Database Analysis
==================================`);

    // Analyze ILI database
    console.log('\nğŸŒ ILI Database Analysis:');
    
    console.log(`ğŸ“Š Total ILI entries: ${allILIs.length}`);
    
    // Analyze ILI status distribution
    const statusCounts = {};
    allILIs.forEach(entry => {
      const status = entry.status || 'active';
      statusCounts[status] = (statusCounts[status] || 0) + 1;
    });
    
    console.log('\nğŸ“Š ILI Status Distribution:');
    Object.entries(statusCounts).forEach(([status, count]) => {
      const percentage = ((count / allILIs.length) * 100).toFixed(2);
      console.log(`  â€¢ ${status}: ${count} entries (${percentage}%)`);
    });
    
    // Analyze definitions
    const entriesWithDefs = allILIs.filter(entry => entry.definition);
    console.log(`\nğŸ“ Entries with definitions: ${entriesWithDefs.length} (${((entriesWithDefs.length / allILIs.length) * 100).toFixed(2)}%)`);

    console.log(`
ğŸ” Example 8: Detailed Synset Content Analysis
=============================================`);

    // Analyze detailed content of synsets
    console.log('\nğŸ” Detailed synset content analysis for "bank":');
    
    const bankSynsets = await synsets('bank');
    console.log(`ğŸ“š Found ${bankSynsets.length} synsets for "bank"`);
    
    // Group by part of speech
    const bankByPOS = {};
    bankSynsets.forEach(synset => {
      const pos = synset.partOfSpeech;
      if (!bankByPOS[pos]) bankByPOS[pos] = [];
      bankByPOS[pos].push(synset);
    });
    
    Object.entries(bankByPOS).forEach(([pos, synsets]) => {
      console.log(`\nğŸ“š ${pos.toUpperCase()} senses (${synsets.length}):`);
      synsets.forEach(async (synset, index) => {
        await displaySynset(synset, index + 1);
      });
    });

    console.log(`
ğŸ‰ Database Statistics Demo Completed!

ğŸ’¡ Key Insights:
   â€¢ Database contains extensive lexical data across multiple languages
   â€¢ ILI provides comprehensive cross-language concept mapping
   â€¢ Synset sizes vary significantly, indicating rich lexical relationships
   â€¢ Part-of-speech distribution shows balanced coverage
   â€¢ Data quality metrics help assess resource suitability
   â€¢ Detailed synset content enables comprehensive analysis

ğŸš€ Practical Applications:
   â€¢ Data quality assessment for research projects
   â€¢ System design and capacity planning
   â€¢ Resource selection for specific applications
   â€¢ Academic research and analysis
   â€¢ Lexical database development

ğŸ“Š Final Statistics:
   â€¢ Total words: ${stats.totalWords}
   â€¢ Total synsets: ${stats.totalSynsets}
   â€¢ Total senses: ${stats.totalSenses}
   â€¢ Total ILI entries: ${stats.totalILIs}
   â€¢ Total lexicons: ${stats.totalLexicons}
   â€¢ Languages covered: ${Object.keys(lexiconsByLanguage).length}
   â€¢ ILI coverage: ${qualityMetrics.iliCoveragePercentage.toFixed(2)}%
`);

    await safeClose(wordnet);
  } catch (error) {
    console.error('âŒ Database statistics demo failed:', error.message);
    await safeClose(wordnet);
    throw error;
  }
}

// Run the database statistics demo
runDemo(demonstrateDatabaseStatistics, 'Database Statistics Demo').catch(error => {
  console.error('âŒ Fatal error:', error.message);
  process.exit(1);
}); 
